# This config file contains the specific settings for this orthoseg project.
#
# The config used for an orthoseg project is loaded in the following order:
#   1) the project defaults as "hardcoded" in orthoseg (project_defaults.ini)
#   2) any .ini files specified in the general.extra_config_files_to_load 
#      parameter (in this file).
#   3) this config file
# Parameters specified in a config file loaded later in the order above
# overrule the corresponding parameter values specified in a previously 
# loaded config file.

# General settings.
[general]

# Extra config files to load for this project. They will be loaded in the 
# order specified and can be specified one path per line, comma seperated.
# If a relative path is used it will be resolved towards the parent dir of 
# this file.
extra_config_files_to_load = ../project_defaults_overrule.ini

# The subject that will be segmented.
segment_subject = footballfields

# Settings concerning the neural network model you want to use for the 
# segmentation. 
[model]
# The segmentation architecture to use. 
# 
# The architectures currently supported by orthoseg follow the encoder-decoder 
# principle:
#   * an encoder: a (deep) neural network that detects features on object level
#   * a decoder: a (deep) neural network that converts the detected features 
#     on object level to a segmentation on pixel level
#
# To configure an encoder/decoder architecture in orthoseg, specify the it in 
# the following way: architecture = {encoder}+{decoder}
#
# There are a lot of encoders and decoders supported.
# For starters, the following encoder/decoder combinations are available:
#   * decoder: unet
#   * encoder: unet, ternaus 
# In the configuration, this can be specified as such, eg.:
#   * architecture = standard+unet
#
# Additionally, all encoders/decoders as provided by the 'segmentation_models'
# project (https://github.com/qubvel/segmentation_models#models-and-backbones) 
# can be used. 
# In the configuration below, use the "backbone" as encoder, and the "model" 
# as decoder, eg.:
#   * architecture = inceptionresnetv2+unet
architecture = mobilenetv2+linknet

# Settings concerning the train process.
[train]
# FOR THIS TEST PROJECT, FORCE 1 EXTRA TRAIN EPOCH ON THE EXISTING 
# MODEL + SAVE IT

# Preload model with the best model trained on previous train data
preload_with_previous_traindata = False

# Force to use a model trained on this traindata version (-1 to disable)
force_model_traindata_id = -1
# Resume training on the best existing model of current train data version
resume_train = False
# Train a model, even if a model exists already 
force_train = False

# The batch size to use during fit of model. 
# Depends on available hardware, model used and image size.
batch_size_fit = 1
# The batch size to use while predicting in the train process. 
# Depends on available hardware, model used and image size.
batch_size_predict = 1

# True to only keep the best model during training
save_best_only = False
# Minimum accuracy to save, (0 = always save)
save_min_accuracy = 0

# Number of epochs to train with some frozen layers. Keeps pretrained layers 
# intact, which is especially usefull for the first few (2-10) epochs when 
# big adjustments are made to the network. Training is also 20% faster during 
# these epochs.   
nb_epoch_with_freeze = 0
# Maximum number of epochs to train (without frozen layers). 
# These epochs are in addition to nb_epoch_with_freeze.
max_epoch = 1
